{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "God's Ass.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WF1cajj5PWMO",
        "qYF2Gmb4PYXU",
        "Aenj5vVybO92"
      ],
      "mount_file_id": "1WgC09RY5K-K5t9MBUnb4AAUIMTTlxtRW",
      "authorship_tag": "ABX9TyPvujsVrbV5FBHNMZTFkp6h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antagonisuto/thesis-code/blob/main/God's_Ass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7GImIevJIEjR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import scipy.io"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "HXAfZbURPUHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Auditory \n",
        "  ________________________\n",
        "  Active \n",
        "\n",
        "  - au_ac_train_X - (14, 540, 32, 101)\n",
        "  - au_ac_train_y - (14, 540, 2)\n",
        "  - au_ac_test_X - (14, 200, 32, 101)\n",
        "  - au_ac_test_y - (14, 200, 2)\n",
        "  ________________________\n",
        "  Passive\n",
        "\n",
        "  - au_pa_train_X - (12, 540, 32, 101)\n",
        "  - au_pa_train_y - (12, 540, 2)\n",
        "  - au_pa_test_X - (12, 200, 32, 101)\n",
        "  - au_pa_test_y - (12, 200, 2)\n",
        "\n",
        "  Exc: 0 and 4 Subjects:\n",
        "\n",
        "  - au_pa_train_X_0 etc 450 train\n",
        "  - au_pa_train_X_6 etc 611 train\n",
        "\n",
        "___________________________________________\n",
        "\n",
        "\n",
        "* Visual\n",
        "\n",
        "  ________________________\n",
        "  Active\n",
        "\n",
        "  - vi_ac_train_X - (13, 540, 32, 101)\n",
        "  - vi_ac_train_y - (13, 540, 2)\n",
        "  - vi_ac_test_X - (13, 200, 32, 101)\n",
        "  - vi_ac_test_y - (13, 200, 2)\n",
        "\n",
        "  Exc: 4 Subject: \n",
        "\n",
        "  - vi_ac_train_4 - 462\n",
        "  ________________________\n",
        "\n",
        "  Passive\n",
        "\n",
        "  - vi_pa_train_X - (13, 540, 32, 101)\n",
        "  - vi_pa_train_y - (13, 540, 2)\n",
        "  - vi_pa_test_X - (13, 200, 32, 101)\n",
        "  - vi_pa_test_y - (13, 200, 2)\n",
        "\n",
        "  Exc: 4 Subject: \n",
        "\n",
        "  - vi_pa_train_4 - 582\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vh7nCS6xY_ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataPath = '/content/drive/MyDrive/databbci/data_mat/'"
      ],
      "metadata": {
        "id": "hNB7bItEIR5E"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auditory"
      ],
      "metadata": {
        "id": "WF1cajj5PWMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Active"
      ],
      "metadata": {
        "id": "tL-dyP_GRnpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mat_train_x = scipy.io.loadmat(dataPath+'au_ac_traing.mat')\n",
        "mat_test_x = scipy.io.loadmat(dataPath+'au_ac_test.mat')"
      ],
      "metadata": {
        "id": "36i8YpNuIpMw"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "au_ac_train_X = np.zeros([14, 540, 32, 101])\n",
        "au_ac_test_X = np.zeros([14, 200, 32, 101])\n",
        "au_ac_train_y = np.zeros([14, 540, 2])\n",
        "au_ac_test_y = np.zeros([14, 200, 2])\n",
        "# mat_train_x['au_ac_traing'][0][1][0][0][0].shape\n",
        "# append(mat_train_x['au_ac_traing'][0][1][0][0][0])"
      ],
      "metadata": {
        "id": "nRT5nx0NPneU"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(14):\n",
        "  au_ac_train_X[i] = mat_train_x['au_ac_traing'][0][i][0][0][0].reshape(540, 32, 101)\n",
        "  au_ac_test_X[i] = mat_test_x['au_ac_test'][0][i][0][0][0].reshape(200, 32, 101)\n",
        "  au_ac_train_y[i] = mat_train_x['au_ac_traing'][0][i][0][0][1]\n",
        "  au_ac_test_y[i] = mat_test_x['au_ac_test'][0][i][0][0][1]"
      ],
      "metadata": {
        "id": "05QdgW0KQs3R"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "au_ac_train_X.shape, au_ac_train_y.shape, au_ac_test_X.shape, au_ac_test_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCjITp3ROg_h",
        "outputId": "d5f7a16b-22f6-4c6a-8781-02c8d97130d8"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14, 540, 32, 101), (14, 540, 2), (14, 200, 32, 101), (14, 200, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passive"
      ],
      "metadata": {
        "id": "Kn5ipBwFRqoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mat_train_x = scipy.io.loadmat(dataPath+'au_pa_traing.mat')\n",
        "mat_test_x = scipy.io.loadmat(dataPath+'au_pa_test.mat')\n",
        "\n",
        "au_pa_train_X = np.zeros([14, 540, 32, 101])\n",
        "au_pa_test_X = np.zeros([14, 200, 32, 101])\n",
        "au_pa_train_y = np.zeros([14, 540, 2])\n",
        "au_pa_test_y = np.zeros([14, 200, 2])\n",
        "\n",
        "mat_train_x['au_pa_traing'][0][0][0][0][0].shape\n",
        "mat_test_x['au_pa_test'][0][0][0][0][0].shape\n",
        "deleted = []\n",
        "\n",
        "for i in range(14):\n",
        "  if mat_train_x['au_pa_traing'][0][i][0][0][0].shape[2]!=540:\n",
        "    print(i)\n",
        "    deleted.append(i)\n",
        "  else:\n",
        "    au_pa_train_X[i] = mat_train_x['au_pa_traing'][0][i][0][0][0].reshape(540, 32, 101)\n",
        "    au_pa_test_X[i] = mat_test_x['au_pa_test'][0][i][0][0][0].reshape(200, 32, 101)\n",
        "    au_pa_train_y[i] = mat_train_x['au_pa_traing'][0][i][0][0][1]\n",
        "    au_pa_test_y[i] = mat_test_x['au_pa_test'][0][i][0][0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYdXPDKqRr9r",
        "outputId": "b7100b94-27e3-4d6f-934a-409964be6f2a"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in deleted:\n",
        "  print(i)\n",
        "  au_pa_train_X = np.delete(au_pa_train_X, i, 0)\n",
        "  au_pa_test_X = np.delete(au_pa_test_X, i, 0)\n",
        "  au_pa_train_y = np.delete(au_pa_train_y, i, 0)\n",
        "  au_pa_test_y = np.delete(au_pa_test_y, i, 0)\n",
        "\n",
        "\n",
        "au_pa_train_X.shape, au_pa_test_X.shape, au_pa_train_y.shape, au_pa_test_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUfwtzh-VVbT",
        "outputId": "399b9d09-6752-4279-9125-8c750106a077"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "6\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12, 540, 32, 101), (12, 200, 32, 101), (12, 540, 2), (12, 200, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "au_pa_train_X.shape, au_pa_train_y.shape, au_pa_test_X.shape, au_pa_test_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ1udsa8SPyW",
        "outputId": "d0ea02b4-e4a2-4e1a-86b3-daeb2734982a"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12, 540, 32, 101), (12, 540, 2), (12, 200, 32, 101), (12, 200, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mat_train_x['au_pa_traing'][0][0][0][0][0].shape)\n",
        "print(mat_train_x['au_pa_traing'][0][6][0][0][0].shape)\n",
        "print(mat_test_x['au_pa_test'][0][0][0][0][0].shape)\n",
        "print(mat_test_x['au_pa_test'][0][6][0][0][0].shape)\n",
        "\n",
        "au_pa_train_X_0 = mat_train_x['au_pa_traing'][0][0][0][0][0].reshape(450, 32, 101)\n",
        "au_pa_test_X_0 = mat_test_x['au_pa_test'][0][0][0][0][0].reshape(200, 32, 101)\n",
        "au_pa_train_y_0 = mat_train_x['au_pa_traing'][0][0][0][0][1]\n",
        "au_pa_test_y_0 = mat_test_x['au_pa_test'][0][0][0][0][1]\n",
        "\n",
        "au_pa_train_X_6 = mat_train_x['au_pa_traing'][0][6][0][0][0].reshape(611, 32, 101)\n",
        "au_pa_test_X_6 = mat_test_x['au_pa_test'][0][6][0][0][0].reshape(200, 32, 101)\n",
        "au_pa_train_y_6 = mat_train_x['au_pa_traing'][0][6][0][0][1]\n",
        "au_pa_test_y_6 = mat_test_x['au_pa_test'][0][6][0][0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlzmRrjkSwBi",
        "outputId": "5a705ec0-aab7-4aa3-a420-75e06a9e4954"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(101, 32, 450)\n",
            "(101, 32, 611)\n",
            "(101, 32, 200)\n",
            "(101, 32, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visual"
      ],
      "metadata": {
        "id": "qYF2Gmb4PYXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Active"
      ],
      "metadata": {
        "id": "GN5sfTa1Yfdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mat_train_x = scipy.io.loadmat(dataPath+'vi_ac_traing.mat')\n",
        "mat_test_x = scipy.io.loadmat(dataPath+'vi_ac_test.mat')\n",
        "\n",
        "vi_ac_train_X = np.zeros([14, 540, 32, 101])\n",
        "vi_ac_test_X = np.zeros([14, 200, 32, 101])\n",
        "vi_ac_train_y = np.zeros([14, 540, 2])\n",
        "vi_ac_test_y = np.zeros([14, 200, 2])\n",
        "\n",
        "# mat_train_x['vi_ac_traing'][0][0][0][0][0].shape\n",
        "# mat_test_x['vi_ac_test'][0][0][0][0][0].shape\n",
        "\n",
        "deleted = []\n",
        "for i in range(14):\n",
        "  if mat_train_x['vi_ac_traing'][0][i][0][0][0].shape[2]!=540:\n",
        "    print(i)\n",
        "    deleted.append(i)\n",
        "  else:\n",
        "    vi_ac_train_X[i] = mat_train_x['vi_ac_traing'][0][i][0][0][0].reshape(540, 32, 101)\n",
        "    vi_ac_test_X[i] = mat_test_x['vi_ac_test'][0][i][0][0][0].reshape(200, 32, 101)\n",
        "    vi_ac_train_y[i] = mat_train_x['vi_ac_traing'][0][i][0][0][1]\n",
        "    vi_ac_test_y[i] = mat_test_x['vi_ac_test'][0][i][0][0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rIdBlCBYg6W",
        "outputId": "85305939-c817-49eb-90ea-dd38518af013"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in deleted:\n",
        "  print(i)\n",
        "  vi_ac_train_X = np.delete(vi_ac_train_X, i, 0)\n",
        "  vi_ac_test_X = np.delete(vi_ac_test_X, i, 0)\n",
        "  vi_ac_train_y = np.delete(vi_ac_train_y, i, 0)\n",
        "  vi_ac_test_y = np.delete(vi_ac_test_y, i, 0)\n",
        "\n",
        "vi_ac_train_X_4 = mat_train_x['vi_ac_traing'][0][4][0][0][0].reshape(-1, 32, 101)\n",
        "vi_ac_test_X_4 = mat_test_x['vi_ac_test'][0][4][0][0][0].reshape(-1, 32, 101)\n",
        "vi_ac_train_y_4 = mat_train_x['vi_ac_traing'][0][4][0][0][1]\n",
        "vi_ac_test_y_4 = mat_test_x['vi_ac_test'][0][4][0][0][1]\n",
        "\n",
        "vi_ac_train_X.shape, vi_ac_test_X.shape, vi_ac_train_y.shape, vi_ac_test_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "civau722Yvko",
        "outputId": "c445bb0b-a5af-4c8d-a78c-bb70339449de"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13, 540, 32, 101), (13, 200, 32, 101), (13, 540, 2), (13, 200, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vi_ac_train_X_4.shape, vi_ac_test_X_4.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSRbsOnbadEL",
        "outputId": "d9003204-6d85-4d0c-dcae-d0f306cbedc5"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((462, 32, 101), (200, 32, 101))"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passive"
      ],
      "metadata": {
        "id": "ATiwaTkuYePj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mat_train_x = scipy.io.loadmat(dataPath+'vi_pa_traing.mat')\n",
        "mat_test_x = scipy.io.loadmat(dataPath+'vi_pa_test.mat')\n",
        "\n",
        "vi_pa_train_X = np.zeros([14, 540, 32, 101])\n",
        "vi_pa_test_X = np.zeros([14, 200, 32, 101])\n",
        "vi_pa_train_y = np.zeros([14, 540, 2])\n",
        "vi_pa_test_y = np.zeros([14, 200, 2])\n",
        "\n",
        "mat_train_x['vi_pa_traing'][0][0][0][0][0].shape\n",
        "mat_test_x['vi_pa_test'][0][0][0][0][0].shape\n",
        "\n",
        "deleted = []\n",
        "for i in range(14):\n",
        "  if mat_train_x['vi_pa_traing'][0][i][0][0][0].shape[2]!=540:\n",
        "    print(i)\n",
        "    deleted.append(i)\n",
        "  else:\n",
        "    vi_pa_train_X[i] = mat_train_x['vi_pa_traing'][0][i][0][0][0].reshape(540, 32, 101)\n",
        "    vi_pa_test_X[i] = mat_test_x['vi_pa_test'][0][i][0][0][0].reshape(200, 32, 101)\n",
        "    vi_pa_train_y[i] = mat_train_x['vi_pa_traing'][0][i][0][0][1]\n",
        "    vi_pa_test_y[i] = mat_test_x['vi_pa_test'][0][i][0][0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ostWrzWPZMH",
        "outputId": "fb78740a-bb30-4539-9c56-99c26041cfed"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in deleted:\n",
        "  print(i)\n",
        "  vi_pa_train_X = np.delete(vi_pa_train_X, i, 0)\n",
        "  vi_pa_test_X = np.delete(vi_pa_test_X, i, 0)\n",
        "  vi_pa_train_y = np.delete(vi_pa_train_y, i, 0)\n",
        "  vi_pa_test_y = np.delete(vi_pa_test_y, i, 0)\n",
        "\n",
        "vi_pa_train_X_4 = mat_train_x['vi_pa_traing'][0][4][0][0][0].reshape(-1, 32, 101)\n",
        "vi_pa_test_X_4 = mat_test_x['vi_pa_test'][0][4][0][0][0].reshape(-1, 32, 101)\n",
        "vi_pa_train_y_4 = mat_train_x['vi_pa_traing'][0][4][0][0][1]\n",
        "vi_pa_test_y_4 = mat_test_x['vi_pa_test'][0][4][0][0][1]\n",
        "\n",
        "vi_pa_train_X.shape, vi_pa_test_X.shape, vi_pa_train_y.shape, vi_pa_test_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1fM0amcW-7c",
        "outputId": "778e139d-415a-4c08-f543-2e9b4cb7cf45"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13, 540, 32, 101), (13, 200, 32, 101), (13, 540, 2), (13, 200, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vi_pa_train_X_4.shape, vi_pa_test_X_4.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjrnZ7EnasS9",
        "outputId": "0eba527b-ef93-40f0-9692-067980ea39c4"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((582, 32, 101), (200, 32, 101))"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **--------------------Code -------------------**"
      ],
      "metadata": {
        "id": "DWz2NmNtbHcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "c-K4FEtNeshW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "fzxuENXeeuyw"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vis_acc_loss(cnn_train):\n",
        "  accuracy = cnn_train.history['accuracy']\n",
        "  val_accuracy = cnn_train.history['val_accuracy']\n",
        "  loss = cnn_train.history['loss']\n",
        "  val_loss = cnn_train.history['val_loss']\n",
        "  epochs = range(len(accuracy))\n",
        "  plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
        "  plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.legend()\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Qtc-wI60oL_I"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vis_confusion_matrix(cm):\n",
        "\n",
        "\n",
        "  ax = sns.heatmap(cm, annot=True, \n",
        "            fmt='', cmap='Blues')\n",
        "  \n",
        "  # group_counts = [\"{0:0.0f}\".format(value) for value in\n",
        "  #                 confusion_matrix.flatten()]\n",
        "\n",
        "  # labels = [f\"{v1}\\n\" for v1 in zip(group_counts)]\n",
        "\n",
        "  # labels = np.asarray(labels).reshape(2,2)\n",
        "  \n",
        "  ax.set_title('CNN Confusion Matrix \\n\\n');\n",
        "  ax.set_xlabel('\\nPredicted Values')\n",
        "  ax.set_ylabel('Actual Values ');\n",
        "\n",
        "  ## Ticket labels - List must be in alphabetical order\n",
        "  ax.xaxis.set_ticklabels(['NI','AC'])\n",
        "  ax.yaxis.set_ticklabels(['NI','AC'])\n",
        "\n",
        "  ## Display the visualization of the Confusion Matrix.\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "rM1fR1wjoMh8"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDA"
      ],
      "metadata": {
        "id": "Aenj5vVybO92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def get_lda(train_X, test_X, train_y, test_y, labels):\n",
        "  n = train_X.shape[0]\n",
        "  train_lda = train_X.reshape(n, 32*101)\n",
        "  n = test_X.shape[0]\n",
        "  test_lda = test_X.reshape(n, 32*101)\n",
        "\n",
        "  train_y = np.argmax(train_y, axis=1)\n",
        "  test_y = np.argmax(test_y, axis=1)\n",
        "\n",
        "\n",
        "  clf = LDA()\n",
        "  clf.fit(train_lda, train_y)\n",
        "\n",
        "  y_pred = clf.predict(test_lda)\n",
        "  print(y_pred.shape)\n",
        "  cm = confusion_matrix(test_y, y_pred)\n",
        "  print(cm)\n",
        "  print('Accuracy' + str(accuracy_score(test_y, y_pred)))\n",
        "\n",
        "  plt.figure()\n",
        "  plot_confusion_matrix(cm)  \n",
        "  plt.show()\n",
        "\n",
        "  # return clf, cm"
      ],
      "metadata": {
        "id": "hHoNSIzbbYJn"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('np.argmax(a, axis=1): {0}'.format(np.argmax(au_ac_train_y[0], axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OZnimbPdfaQ",
        "outputId": "67c4f192-af8c-4ef2-addd-9daf72a08487"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "np.argmax(a, axis=1): [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
            " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(14):\n",
        "  print('**************************************************')\n",
        "  print('Subject', i)\n",
        "\n",
        "  get_lda(au_ac_train_X[i], au_ac_test_X[i], au_ac_train_y[i], au_ac_test_y[i], labels=['ignore', 'active'])"
      ],
      "metadata": {
        "id": "Yiz0P9nhc7CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "pkNaNgTCnHTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "import sklearn.metrics as metrics\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "from tensorflow.keras import utils as np_utils"
      ],
      "metadata": {
        "id": "VEpFBa4UnoE9"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_ieee(train_X, test_X, train_y, test_y, batch_size = 32, epochs = 100, ver = 1):\n",
        "  train_X = train_X.reshape(-1, 32,101, 1)\n",
        "  test_X = test_X.reshape(-1, 32,101, 1)\n",
        "\n",
        "  #train_X, train_y = shuffle(test_X, test_y, random_state=2)\n",
        "  #test_X, test_y = shuffle(test_X, test_y, random_state=2)\n",
        "  \n",
        "  train_X,valid_X,train_label,valid_label = train_test_split(train_X, \n",
        "                                                             train_y, \n",
        "                                                             test_size=0.2, \n",
        "                                                             random_state=13)\n",
        "\n",
        "  # batch_size = 32\n",
        "  # epochs = 100\n",
        "  num_classes = 2\n",
        "\n",
        "  cnn_model = Sequential()\n",
        "  cnn_model.add(Conv2D(5, kernel_size=(1, 16),activation='relu', input_shape=(32,101,1),padding='same'))\n",
        "  # cnn_model.add(MaxPooling2D((2, 2),padding='same'))\n",
        "  cnn_model.add(BatchNormalization())\n",
        "  cnn_model.add(Dropout(0.25))\n",
        "\n",
        "  cnn_model.add(Conv2D(25, (1, 3), activation='relu',padding='same'))\n",
        "  cnn_model.add(AveragePooling2D(pool_size=(1, 4)))\n",
        "  # cnn_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "  cnn_model.add(BatchNormalization())\n",
        "  cnn_model.add(Dropout(0.25))\n",
        "\n",
        "  cnn_model.add(Conv2D(100, (1, 4), activation='relu',padding='same'))         \n",
        "  # cnn_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "  cnn_model.add(BatchNormalization())\n",
        "  cnn_model.add(Dropout(0.25))\n",
        "\n",
        "  cnn_model.add(Flatten())\n",
        "  cnn_model.add(BatchNormalization())\n",
        "  cnn_model.add(Dense(200, activation='relu'))\n",
        "  cnn_model.add(Dropout(0.25))\n",
        "\n",
        "  cnn_model.add(Dense(100, activation='relu'))\n",
        "  cnn_model.add(Dropout(0.25))\n",
        "  cnn_model.add(Dense(num_classes, activation='sigmoid'))\n",
        "\n",
        "  # set a valid path for your system to record model checkpoints\n",
        "  checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint.h5', verbose=1,\n",
        "                               save_best_only=True)\n",
        "  \n",
        "  y_integers = np.argmax(train_y, axis=1)\n",
        "  class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_integers), y=y_integers)\n",
        "  d_class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "  # opt = SGD(lr=0.0001)\n",
        "  opt = Adam(lr=0.001, decay=0.01)\n",
        "\n",
        "  cnn_model.compile(optimizer=opt,\n",
        "          loss = \"categorical_crossentropy\",\n",
        "          metrics=['accuracy'])\n",
        "  \n",
        "  cnn_train = cnn_model.fit(train_X, train_label, batch_size=batch_size, \n",
        "                          epochs=epochs,\n",
        "                          verbose=ver,\n",
        "                          validation_data=(valid_X, valid_label), \n",
        "                          callbacks=[checkpointer], \n",
        "                          class_weight = d_class_weights\n",
        "                          )\n",
        "\n",
        "  test_eval = cnn_model.evaluate(test_X, test_y, verbose=0)\n",
        "\n",
        "  pred_prob_conv = cnn_model.predict(test_X)\n",
        "\n",
        "  pred_y_conv = np.argmax(pred_prob_conv, axis=1)  # only necessary if output has one-hot-encoding, shape=(n_samples)\n",
        "  test_y_conv = np.argmax(test_y, axis=1)\n",
        "\n",
        "  cm_cnn = cm_cnn = metrics.confusion_matrix(y_true=test_y_conv, \n",
        "                                              y_pred=pred_y_conv)\n",
        "\n",
        "  return cnn_model, cnn_train, test_eval, cm_cnn"
      ],
      "metadata": {
        "id": "rIb2_mffnIi1"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_ieee = []"
      ],
      "metadata": {
        "id": "wU8zSH4coWZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(14):\n",
        "  print('**************************************************')\n",
        "  print('Subject', i)\n",
        "\n",
        "  #CNN\n",
        "  cnn_model, cnn_train, test_eval, cm_cnn = cnn_ieee(au_ac_train_X[i], \n",
        "                                                     au_ac_test_X[i], \n",
        "                                                     au_ac_train_y[i], \n",
        "                                                     au_ac_test_y[i],\n",
        "                                                     batch_size = 64,\n",
        "                                                     epochs = 100,\n",
        "                                                     ver = 1)\n",
        "  \n",
        "  vis_confusion_matrix(cm_cnn)\n",
        "  vis_acc_loss(cnn_train)\n",
        "  print('Test loss:', test_eval[0])\n",
        "  print('Test accuracy:', test_eval[1])\n",
        "  res_ieee.append(test_eval[1])\n",
        "  print('**************************************************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi8lkrm-n6Ap",
        "outputId": "0ebb9913-5e79-479b-af41-d119e6433d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************************************\n",
            "Subject 0\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - ETA: 0s - loss: 3.0033 - accuracy: 0.5556\n",
            "Epoch 1: val_loss improved from inf to 4.18469, saving model to /tmp/checkpoint.h5\n",
            "7/7 [==============================] - 7s 887ms/step - loss: 3.0033 - accuracy: 0.5556 - val_loss: 4.1847 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7645 - accuracy: 0.7662\n",
            "Epoch 2: val_loss improved from 4.18469 to 1.89562, saving model to /tmp/checkpoint.h5\n",
            "7/7 [==============================] - 9s 1s/step - loss: 1.7645 - accuracy: 0.7662 - val_loss: 1.8956 - val_accuracy: 0.5370\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8863 - accuracy: 0.8264\n",
            "Epoch 3: val_loss improved from 1.89562 to 1.67446, saving model to /tmp/checkpoint.h5\n",
            "7/7 [==============================] - 5s 745ms/step - loss: 0.8863 - accuracy: 0.8264 - val_loss: 1.6745 - val_accuracy: 0.3889\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7494 - accuracy: 0.8611\n",
            "Epoch 4: val_loss did not improve from 1.67446\n",
            "7/7 [==============================] - 4s 641ms/step - loss: 0.7494 - accuracy: 0.8611 - val_loss: 1.7094 - val_accuracy: 0.3241\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4836 - accuracy: 0.8843\n",
            "Epoch 5: val_loss did not improve from 1.67446\n",
            "7/7 [==============================] - 4s 641ms/step - loss: 0.4836 - accuracy: 0.8843 - val_loss: 1.6939 - val_accuracy: 0.3056\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4086 - accuracy: 0.9167\n",
            "Epoch 6: val_loss improved from 1.67446 to 1.19353, saving model to /tmp/checkpoint.h5\n",
            "7/7 [==============================] - 5s 730ms/step - loss: 0.4086 - accuracy: 0.9167 - val_loss: 1.1935 - val_accuracy: 0.3426\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2421 - accuracy: 0.9537\n",
            "Epoch 7: val_loss improved from 1.19353 to 1.12650, saving model to /tmp/checkpoint.h5\n",
            "7/7 [==============================] - 5s 725ms/step - loss: 0.2421 - accuracy: 0.9537 - val_loss: 1.1265 - val_accuracy: 0.3333\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3182 - accuracy: 0.9444\n",
            "Epoch 8: val_loss improved from 1.12650 to 1.03986, saving model to /tmp/checkpoint.h5\n",
            "7/7 [==============================] - 5s 727ms/step - loss: 0.3182 - accuracy: 0.9444 - val_loss: 1.0399 - val_accuracy: 0.3611\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2819 - accuracy: 0.9537\n",
            "Epoch 9: val_loss did not improve from 1.03986\n",
            "7/7 [==============================] - 4s 638ms/step - loss: 0.2819 - accuracy: 0.9537 - val_loss: 1.0638 - val_accuracy: 0.3889\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.9514\n",
            "Epoch 10: val_loss improved from 1.03986 to 0.93753, saving model to /tmp/checkpoint.h5\n",
            "7/7 [==============================] - 5s 714ms/step - loss: 0.2057 - accuracy: 0.9514 - val_loss: 0.9375 - val_accuracy: 0.3981\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9699\n",
            "Epoch 11: val_loss improved from 0.93753 to 0.83845, saving model to /tmp/checkpoint.h5\n",
            "7/7 [==============================] - 5s 727ms/step - loss: 0.0860 - accuracy: 0.9699 - val_loss: 0.8384 - val_accuracy: 0.5093\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9606\n",
            "Epoch 12: val_loss did not improve from 0.83845\n",
            "7/7 [==============================] - 4s 633ms/step - loss: 0.0786 - accuracy: 0.9606 - val_loss: 0.8454 - val_accuracy: 0.5370\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1640 - accuracy: 0.9745\n",
            "Epoch 13: val_loss did not improve from 0.83845\n",
            "7/7 [==============================] - 4s 645ms/step - loss: 0.1640 - accuracy: 0.9745 - val_loss: 0.8534 - val_accuracy: 0.5741\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2136 - accuracy: 0.9745\n",
            "Epoch 14: val_loss improved from 0.83845 to 0.72024, saving model to /tmp/checkpoint.h5\n",
            "7/7 [==============================] - 5s 717ms/step - loss: 0.2136 - accuracy: 0.9745 - val_loss: 0.7202 - val_accuracy: 0.6111\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9792\n",
            "Epoch 15: val_loss did not improve from 0.72024\n",
            "7/7 [==============================] - 5s 646ms/step - loss: 0.0706 - accuracy: 0.9792 - val_loss: 0.7349 - val_accuracy: 0.6019\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9769\n",
            "Epoch 16: val_loss did not improve from 0.72024\n",
            "7/7 [==============================] - 4s 641ms/step - loss: 0.0715 - accuracy: 0.9769 - val_loss: 0.8059 - val_accuracy: 0.6111\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1248 - accuracy: 0.9838\n",
            "Epoch 17: val_loss did not improve from 0.72024\n",
            "7/7 [==============================] - 4s 634ms/step - loss: 0.1248 - accuracy: 0.9838 - val_loss: 0.8065 - val_accuracy: 0.6296\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9907\n",
            "Epoch 18: val_loss did not improve from 0.72024\n",
            "7/7 [==============================] - 4s 637ms/step - loss: 0.0230 - accuracy: 0.9907 - val_loss: 0.7877 - val_accuracy: 0.6296\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9769\n",
            "Epoch 19: val_loss did not improve from 0.72024\n",
            "7/7 [==============================] - 4s 626ms/step - loss: 0.0827 - accuracy: 0.9769 - val_loss: 0.7538 - val_accuracy: 0.6481\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.9699\n",
            "Epoch 20: val_loss did not improve from 0.72024\n",
            "7/7 [==============================] - 4s 634ms/step - loss: 0.1295 - accuracy: 0.9699 - val_loss: 0.7257 - val_accuracy: 0.6574\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9861\n",
            "Epoch 21: val_loss improved from 0.72024 to 0.71819, saving model to /tmp/checkpoint.h5\n",
            "7/7 [==============================] - 5s 725ms/step - loss: 0.0357 - accuracy: 0.9861 - val_loss: 0.7182 - val_accuracy: 0.6389\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9769\n",
            "Epoch 22: val_loss improved from 0.71819 to 0.68114, saving model to /tmp/checkpoint.h5\n",
            "7/7 [==============================] - 5s 713ms/step - loss: 0.1188 - accuracy: 0.9769 - val_loss: 0.6811 - val_accuracy: 0.7037\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9838\n",
            "Epoch 23: val_loss improved from 0.68114 to 0.67611, saving model to /tmp/checkpoint.h5\n",
            "7/7 [==============================] - 5s 797ms/step - loss: 0.0357 - accuracy: 0.9838 - val_loss: 0.6761 - val_accuracy: 0.6944\n",
            "Epoch 24/100\n",
            "2/7 [=======>......................] - ETA: 3s - loss: 0.0598 - accuracy: 0.9844"
          ]
        }
      ]
    }
  ]
}